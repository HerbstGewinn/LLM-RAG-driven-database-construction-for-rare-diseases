# Readme
## Overview
This application uses a local Retrieval-Augmented Generation (RAG) method to extract information from a PDF document and answer questions based on it. The implementation utilizes the Ollama library for embeddings and answer generation, without requiring an API key from OpenAI. All steps are executed locally, using an integrated vector store to store the context and retrieve relevant information quickly.

## Background
The initial plan was to develop an API-based application, but OpenAI has removed the initial credits for new users in recent months, making it difficult to fully test the first version. As a result, the application was rewritten to enable a local RAG application using Ollama.

## Functionality
### PDF Loading and Conversion to Text
The PDF is loaded, and its content is converted into a string. 

### Text Splitting
The extracted text is split into smaller segments (chunks) to enable efficient processing and searching. Each segment is converted into a Document object.

### Vectorization and Storage
The text segments are converted into vectors using OllamaEmbeddings. These vectors are then stored in an in-memory vector store for fast querying.

### Retriever Creation
The vector store is transformed into a Retriever, which allows for the quick retrieval of relevant text passages for later question answering.

### Question Answering with RAG
Using a RAG pipeline (consisting of a retrieval module and an LLM model), an answer to a given question is generated. The context for the answer is provided by the Retriever, and the answer is generated by a pre-trained LLM model (llama3.1:8b).

## Requirements

To install Ollama, run the following command in the terminal:

```curl -fsSL https://ollama.com/install.sh | sh```

To pull the model llama3.1, use the following command:

```ollama pull llama3.1:8b```

To pull the text embedding model, use:

```ollama pull nomic-embed-text```

The following packages need to be installed:

```pip install -qU langchain_community pypdf```

```pip install -qU langchain-text-splitters```

```pip install -U langchain-core```

```pip install langchain```

```pip install -qU langchain langchain_community```

```pip install -qU langchain_ollama```


If you have an API key available for testing, install the OpenAI package with:

```pip install -qU langchain-openai```

## Usage
```python rag_test_alternative.py /path/file.pdf```



